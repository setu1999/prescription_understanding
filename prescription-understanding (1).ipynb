{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11932511,"sourceType":"datasetVersion","datasetId":7502016},{"sourceId":12602657,"sourceType":"datasetVersion","datasetId":7960307}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages\n!pip install torch transformers pandas tqdm sentence-transformers rouge-score sacremoses sacrebleu bert-score\n\n# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom transformers import BioGptTokenizer, BioGptForCausalLM\nfrom rouge_score import rouge_scorer\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bertscore\nimport sacrebleu\n\n# Load model and tokenizer\ntokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\nmodel = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Load data\ndf = pd.read_csv(\"/kaggle/input/precription/health prescription data.csv\")\ndf = df[['SUBJECT_ID', 'ROW_ID', 'HADM_ID', 'CATEGORY', 'ADMISSION_TYPE', 'DIAGNOSIS', 'TEXT']].dropna(subset=['TEXT']).reset_index(drop=True)\n\n# Sample subset\nsample_df = df.sample(n=30, random_state=42).reset_index(drop=True)\n\n# Clarification function\ndef clarify_text(text, max_new_tokens=200):\n    prompt = f\"Summarize clearly this medical report:\\n\\n{text}\\n\\nSummary:\"\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024 - max_new_tokens,\n        padding=\"max_length\"\n    ).to(device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9\n    )\n\n    clarified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return clarified_text.replace(prompt, \"\").strip()\n\n# Generate summaries\nclarified_summaries = []\nfor report in tqdm(sample_df['TEXT'], desc=\"Clarifying Medical Reports\"):\n    clarified = clarify_text(report)\n    clarified_summaries.append(clarified)\n\nsample_df['clarified_summary'] = clarified_summaries\n\n# Initialize evaluation tools\nrouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nembed_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\nrougeL_scores = []\ncosine_scores = []\noriginal_texts = sample_df['TEXT'].tolist()\nclarified_texts = sample_df['clarified_summary'].tolist()\n\n# Compute embeddings\noriginal_embeddings = embed_model.encode(original_texts, convert_to_tensor=True)\nclarified_embeddings = embed_model.encode(clarified_texts, convert_to_tensor=True)\n\n# Compute ROUGE-L and Cosine Similarity\nfor orig, clar, orig_emb, clar_emb in tqdm(zip(original_texts, clarified_texts, original_embeddings, clarified_embeddings), total=len(original_texts)):\n    rougeL_score = rouge.score(orig, clar)['rougeL'].fmeasure\n    rougeL_scores.append(rougeL_score)\n    cosine_sim = util.cos_sim(orig_emb, clar_emb).item()\n    cosine_scores.append(cosine_sim)\n\navg_rougeL = np.mean(rougeL_scores)\navg_cosine_similarity = np.mean(cosine_scores)\n\nprint(f\"\\nAverage ROUGE-L: {avg_rougeL:.4f}\")\nprint(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n\n# BLEU evaluation\nbleu = sacrebleu.corpus_bleu(clarified_texts, [original_texts])\nbleu_score = bleu.score\nprint(f\"Average BLEU: {bleu_score:.4f}\")\n\n# BERTScore evaluation\nP, R, F1 = bertscore(clarified_texts, original_texts, lang=\"en\")\navg_bertscore_f1 = F1.mean().item()\nprint(f\"Average BERTScore F1: {avg_bertscore_f1:.4f}\")\n\n# Save results\nsample_df.to_csv(\"clarified_medical_reports_full_evaluation.csv\", index=False)\nprint(\"Saved extended evaluations to clarified_medical_reports_full_evaluation.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:22:55.366765Z","iopub.execute_input":"2025-07-28T16:22:55.366999Z","iopub.status.idle":"2025-07-28T16:25:43.368837Z","shell.execute_reply.started":"2025-07-28T16:22:55.366974Z","shell.execute_reply":"2025-07-28T16:25:43.368138Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c387bac6036a113b14c480d9ce2d0148cea8e29cb7e69c2c0a1ca9491ca605ad\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: sacremoses, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sacrebleu, rouge-score, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.2.0 rouge-score-0.1.2 sacrebleu-2.5.1 sacremoses-0.1.1\n","output_type":"stream"},{"name":"stderr","text":"2025-07-28 16:24:24.063292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753719864.254696      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753719864.322010      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5591188462764beb9b798fba510f4669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd2d2a0307a45d787ed9dfba6ab7848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/595 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a5d97ac68ef4787bf0632c183d71f2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32b008219e334e34a1df33ba6d94b90c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6e07342eb64308a2db794d1f5aac47"}},"metadata":{}},{"name":"stderr","text":"\nClarifying Medical Reports:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\nClarifying Medical Reports:   3%|▎         | 1/30 [00:02<01:25,  2.94s/it]\u001b[A\nClarifying Medical Reports:   7%|▋         | 2/30 [00:05<01:18,  2.81s/it]\u001b[A\nClarifying Medical Reports:  10%|█         | 3/30 [00:06<00:48,  1.78s/it]\u001b[A\nClarifying Medical Reports:  13%|█▎        | 4/30 [00:06<00:31,  1.22s/it]\u001b[A\nClarifying Medical Reports:  17%|█▋        | 5/30 [00:07<00:28,  1.14s/it]\u001b[A\nClarifying Medical Reports:  20%|██        | 6/30 [00:08<00:23,  1.04it/s]\u001b[A\nClarifying Medical Reports:  23%|██▎       | 7/30 [00:08<00:17,  1.34it/s]\u001b[A\nClarifying Medical Reports:  27%|██▋       | 8/30 [00:08<00:12,  1.72it/s]\u001b[A\nClarifying Medical Reports:  30%|███       | 9/30 [00:08<00:09,  2.21it/s]\u001b[A\nClarifying Medical Reports:  33%|███▎      | 10/30 [00:11<00:21,  1.08s/it]\u001b[A\nClarifying Medical Reports:  37%|███▋      | 11/30 [00:12<00:20,  1.08s/it]\u001b[A\nClarifying Medical Reports:  40%|████      | 12/30 [00:12<00:14,  1.22it/s]\u001b[A\nClarifying Medical Reports:  43%|████▎     | 13/30 [00:13<00:12,  1.39it/s]\u001b[A\nClarifying Medical Reports:  47%|████▋     | 14/30 [00:16<00:23,  1.44s/it]\u001b[A\nClarifying Medical Reports:  50%|█████     | 15/30 [00:17<00:19,  1.32s/it]\u001b[A\nClarifying Medical Reports:  53%|█████▎    | 16/30 [00:17<00:14,  1.00s/it]\u001b[A\nClarifying Medical Reports:  57%|█████▋    | 17/30 [00:20<00:20,  1.61s/it]\u001b[A\nClarifying Medical Reports:  60%|██████    | 18/30 [00:20<00:14,  1.24s/it]\u001b[A\nClarifying Medical Reports:  63%|██████▎   | 19/30 [00:23<00:19,  1.74s/it]\u001b[A\nClarifying Medical Reports:  67%|██████▋   | 20/30 [00:24<00:12,  1.29s/it]\u001b[A\nClarifying Medical Reports:  70%|███████   | 21/30 [00:24<00:08,  1.05it/s]\u001b[A\nClarifying Medical Reports:  73%|███████▎  | 22/30 [00:24<00:06,  1.23it/s]\u001b[A\nClarifying Medical Reports:  77%|███████▋  | 23/30 [00:25<00:04,  1.56it/s]\u001b[A\nClarifying Medical Reports:  80%|████████  | 24/30 [00:25<00:03,  1.91it/s]\u001b[A\nClarifying Medical Reports:  83%|████████▎ | 25/30 [00:25<00:02,  2.38it/s]\u001b[A\nClarifying Medical Reports:  87%|████████▋ | 26/30 [00:25<00:01,  2.35it/s]\u001b[A\nClarifying Medical Reports:  90%|█████████ | 27/30 [00:26<00:01,  2.77it/s]\u001b[A\nClarifying Medical Reports:  93%|█████████▎| 28/30 [00:26<00:00,  3.05it/s]\u001b[A\nClarifying Medical Reports:  97%|█████████▋| 29/30 [00:26<00:00,  3.04it/s]\u001b[A\nClarifying Medical Reports: 100%|██████████| 30/30 [00:27<00:00,  1.10it/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a3bd07e83b4dff94bb2d1a4ad7d35f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f007359576d48bcaa830da5ad90f631"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a24079817d4755bc2fe78faac8406b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4143ec3eb625476faa06f98b8b6ef511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0143f5933514e34b8d7115f8b84828b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74946ad684034993ab552d93eddea836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b4dff927a0459ca666713946a2a8b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abfe46fe55a94c778f3ccbace83f0a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a11c6df20bb47b381215149ef9ac0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ed42d967164cc5882f5467228b26c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bc32734acca4526842dd943bbe1fde9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e84f874402047d686f81ef1822a648c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"345e826503de4a95bd2891f390b1ff22"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 30/30 [00:07<00:00,  4.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage ROUGE-L: 0.5030\nAverage Cosine Similarity: 0.9830\nAverage BLEU: 9.1410\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b484097011240d4ba1556a72f99fc85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"365276500bd6483a9da679f691659175"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5cfe591d9c4067bb3842033f5b2eb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32eef853b1c74057a78c889bf4baa699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f233d1d3ef4e619e92154628bbe230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394a07f08b2d48448c9450727aa26ef2"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Average BERTScore F1: 0.9008\nSaved extended evaluations to clarified_medical_reports_full_evaluation.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required packages\n!pip install torch transformers pandas tqdm sentence-transformers rouge-score sacremoses sacrebleu bert-score --quiet\n\n# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom rouge_score import rouge_scorer\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bertscore\nimport sacrebleu\n\n# Load model and tokenizer\nbiomedlm_name = \"stanford-crfm/BioMedLM\"\ntokenizer = AutoTokenizer.from_pretrained(biomedlm_name)\ntokenizer.pad_token = tokenizer.eos_token\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForCausalLM.from_pretrained(biomedlm_name).to(device)\nmodel.eval()\n\n# Load data\ndf = pd.read_csv(\"/kaggle/input/precription/health prescription data.csv\")\ndf = df[['SUBJECT_ID', 'ROW_ID', 'HADM_ID', 'CATEGORY', 'ADMISSION_TYPE', 'DIAGNOSIS', 'TEXT']].dropna(subset=['TEXT']).reset_index(drop=True)\n\n# Sample subset\nsample_df = df.sample(n=30, random_state=42).reset_index(drop=True)\n\n# Clarification function\ndef clarify_text(text, max_new_tokens=200):\n    prompt = f\"Summarize clearly this medical report:\\n\\n{text}\\n\\nSummary:\"\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024 - max_new_tokens,\n        padding=\"max_length\"\n    ).to(device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id,\n        eos_token_id=tokenizer.eos_token_id\n    )\n\n    clarified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return clarified_text.replace(prompt, \"\").strip()\n\n# Generate summaries\nclarified_summaries = []\nfor report in tqdm(sample_df['TEXT'], desc=\"Clarifying Medical Reports\"):\n    try:\n        clarified = clarify_text(report)\n    except Exception:\n        clarified = \"\"\n    clarified_summaries.append(clarified)\n\nsample_df['clarified_summary'] = clarified_summaries\n\n# Initialize evaluation tools\nrouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nembed_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\nrougeL_scores = []\ncosine_scores = []\noriginal_texts = sample_df['TEXT'].tolist()\nclarified_texts = sample_df['clarified_summary'].tolist()\n\n# Compute embeddings\noriginal_embeddings = embed_model.encode(original_texts, convert_to_tensor=True)\nclarified_embeddings = embed_model.encode(clarified_texts, convert_to_tensor=True)\n\n# Compute ROUGE-L and Cosine Similarity\nfor orig, clar, orig_emb, clar_emb in tqdm(zip(original_texts, clarified_texts, original_embeddings, clarified_embeddings), total=len(original_texts)):\n    rougeL_score = rouge.score(orig, clar)['rougeL'].fmeasure\n    rougeL_scores.append(rougeL_score)\n    cosine_sim = util.cos_sim(orig_emb, clar_emb).item()\n    cosine_scores.append(cosine_sim)\n\navg_rougeL = np.mean(rougeL_scores)\navg_cosine_similarity = np.mean(cosine_scores)\nprint(f\"\\nAverage ROUGE-L: {avg_rougeL:.4f}\")\nprint(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n\n# BLEU evaluation\nbleu = sacrebleu.corpus_bleu(clarified_texts, [original_texts])\nbleu_score = bleu.score\nprint(f\"Average BLEU: {bleu_score:.4f}\")\n\n# BERTScore evaluation\nP, R, F1 = bertscore(clarified_texts, original_texts, lang=\"en\")\navg_bertscore_f1 = F1.mean().item()\nprint(f\"Average BERTScore F1: {avg_bertscore_f1:.4f}\")\n\n# Show sample output\nprint(sample_df[['TEXT', 'clarified_summary']].head())\n\n# Save results\nsample_df.to_csv(\"clarified_medical_reports_full_evaluation.csv\", index=False)\nprint(\"Saved extended evaluations to clarified_medical_reports_full_evaluation.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:41:14.394763Z","iopub.execute_input":"2025-07-28T16:41:14.394999Z","iopub.status.idle":"2025-07-28T18:08:31.926864Z","shell.execute_reply.started":"2025-07-28T16:41:14.394974Z","shell.execute_reply":"2025-07-28T18:08:31.925996Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"2025-07-28 16:42:42.331072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753720962.509901      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753720962.561092      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/267 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f2b3f2299b407a9d17b3319ddad97d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f15eb2ff5a4830968a5500af9f5aa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70977fdddf1d43e49a84a62df00adb42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825a3201b2394568956890696dd38b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/876 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f191abe0b4340ce9517636ffe84743d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/10.7G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b68982766c9c419b83d1b62233af2b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/10.7G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1035aaba95594fda834cf0943019aa29"}},"metadata":{}},{"name":"stderr","text":"\nClarifying Medical Reports:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\nClarifying Medical Reports:   3%|▎         | 1/30 [02:37<1:16:04, 157.41s/it]\u001b[A\nClarifying Medical Reports:   7%|▋         | 2/30 [05:13<1:13:08, 156.74s/it]\u001b[A\nClarifying Medical Reports:  10%|█         | 3/30 [07:49<1:10:25, 156.51s/it]\u001b[A\nClarifying Medical Reports:  13%|█▎        | 4/30 [10:26<1:07:45, 156.35s/it]\u001b[A\nClarifying Medical Reports:  17%|█▋        | 5/30 [13:01<1:05:03, 156.15s/it]\u001b[A\nClarifying Medical Reports:  20%|██        | 6/30 [15:37<1:02:24, 156.00s/it]\u001b[A\nClarifying Medical Reports:  23%|██▎       | 7/30 [18:13<59:46, 155.92s/it]  \u001b[A\nClarifying Medical Reports:  27%|██▋       | 8/30 [20:48<57:08, 155.84s/it]\u001b[A\nClarifying Medical Reports:  30%|███       | 9/30 [23:24<54:32, 155.82s/it]\u001b[A\nClarifying Medical Reports:  33%|███▎      | 10/30 [26:00<51:56, 155.81s/it]\u001b[A\nClarifying Medical Reports:  37%|███▋      | 11/30 [28:36<49:20, 155.79s/it]\u001b[A\nClarifying Medical Reports:  40%|████      | 12/30 [31:12<46:43, 155.77s/it]\u001b[A\nClarifying Medical Reports:  43%|████▎     | 13/30 [33:47<44:08, 155.78s/it]\u001b[A\nClarifying Medical Reports:  47%|████▋     | 14/30 [36:23<41:32, 155.78s/it]\u001b[A\nClarifying Medical Reports:  50%|█████     | 15/30 [38:59<38:56, 155.77s/it]\u001b[A\nClarifying Medical Reports:  53%|█████▎    | 16/30 [41:35<36:20, 155.76s/it]\u001b[A\nClarifying Medical Reports:  57%|█████▋    | 17/30 [44:10<33:44, 155.77s/it]\u001b[A\nClarifying Medical Reports:  60%|██████    | 18/30 [46:46<31:09, 155.77s/it]\u001b[A\nClarifying Medical Reports:  63%|██████▎   | 19/30 [49:22<28:33, 155.78s/it]\u001b[A\nClarifying Medical Reports:  67%|██████▋   | 20/30 [51:58<25:57, 155.79s/it]\u001b[A\nClarifying Medical Reports:  70%|███████   | 21/30 [54:34<23:22, 155.79s/it]\u001b[A\nClarifying Medical Reports:  73%|███████▎  | 22/30 [57:09<20:46, 155.79s/it]\u001b[A\nClarifying Medical Reports:  77%|███████▋  | 23/30 [59:45<18:10, 155.79s/it]\u001b[A\nClarifying Medical Reports:  80%|████████  | 24/30 [1:02:21<15:34, 155.79s/it]\u001b[A\nClarifying Medical Reports:  83%|████████▎ | 25/30 [1:04:57<12:59, 155.80s/it]\u001b[A\nClarifying Medical Reports:  87%|████████▋ | 26/30 [1:07:33<10:23, 155.81s/it]\u001b[A\nClarifying Medical Reports:  90%|█████████ | 27/30 [1:10:08<07:47, 155.82s/it]\u001b[A\nClarifying Medical Reports:  93%|█████████▎| 28/30 [1:12:44<05:11, 155.83s/it]\u001b[A\nClarifying Medical Reports:  97%|█████████▋| 29/30 [1:15:20<02:35, 155.85s/it]\u001b[A\nClarifying Medical Reports: 100%|██████████| 30/30 [1:17:56<00:00, 155.88s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d6f82cccbb48d5992e379f57e8c617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c503389152d14954bce350d66cb4f287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58488573bf33445f9e1c260bfe5a7d59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b3d8a821573469ababf5d2b315d3381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490d3edd96f74139897f0c0f331d66bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783d0844ab0d4a3a9ec40e18da602ef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb8f8d64c9f24c01a4c4213dada8928a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd327ac0e0f64e5b881f3f9fd44bee3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4987a541eefd4212bcf62855931f90c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b634073def1435fb125aac8edfb2dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee03c6816a0450ab2b13b648e2865a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c758c01f8a4c26a4724a45be712b5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2da40e029cd43cba8462361b5a79e0b"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 30/30 [00:06<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage ROUGE-L: 0.4312\nAverage Cosine Similarity: 0.9830\nAverage BLEU: 6.3302\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d420cb5421df43ae9d9f9e626a91b77a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"898e0731111c4143abca35365ca275f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"884c7b629582432e88766912e77a1fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05edda605414d5dabb6a6febfb6680f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bc02b45274c49029258631de09bce34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4c91f9d97749159156b4eac298f25c"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Average BERTScore F1: 0.9876\n                                                TEXT  \\\n0  Admission Date:  [**2192-5-20**]              ...   \n1  Admission Date:  [**2137-12-5**]              ...   \n2  Admission Date:  [**2152-10-19**]             ...   \n3  Admission Date:  [**2129-5-23**]              ...   \n4  Admission Date:  [**2184-6-23**]              ...   \n\n                                   clarified_summary  \n0  Summarize clearly this medical report:\\n\\nAdmi...  \n1  Summarize clearly this medical report:\\n\\nAdmi...  \n2  Summarize clearly this medical report:\\n\\nAdmi...  \n3  Summarize clearly this medical report:\\n\\nAdmi...  \n4  Summarize clearly this medical report:\\n\\nAdmi...  \nSaved extended evaluations to clarified_medical_reports_full_evaluation.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required packages\n!pip install torch transformers pandas tqdm sentence-transformers rouge-score sacremoses sacrebleu bert-score --quiet\n\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom rouge_score import rouge_scorer\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bertscore\nimport sacrebleu\n\n# Load MedAlpaca model and tokenizer\nmodel_name = \"medalpaca/medalpaca-7b\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n    device_map=\"auto\"\n)\nmodel.eval()\n\n# Load dataset and sample subset\ndf = pd.read_csv(\"/kaggle/input/precription/health prescription data.csv\")\ndf = df[['SUBJECT_ID', 'ROW_ID', 'HADM_ID', 'CATEGORY', 'ADMISSION_TYPE', 'DIAGNOSIS', 'TEXT']].dropna(subset=['TEXT']).reset_index(drop=True)\nsample_df = df.sample(n=30, random_state=42).reset_index(drop=True)\n\n# Clarification function\ndef clarify_text_medalpaca(text, max_new_tokens=100):\n    prompt = f\"### Instruction:\\nSummarize the following medical report clearly and concisely.\\n\\n### Input:\\n{text}\\n\\n### Response:\"\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024 - max_new_tokens,\n        padding=\"max_length\"\n    ).to(device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        pad_token_id=tokenizer.eos_token_id,\n        eos_token_id=tokenizer.eos_token_id\n    )\n\n    clarified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return clarified_text.replace(prompt, \"\").strip()\n\n# Clarify medical reports\nclarified_summaries = []\nfor report in tqdm(sample_df['TEXT'], desc=\"Clarifying Medical Reports\"):\n    try:\n        clarified = clarify_text_medalpaca(report)\n    except Exception:\n        clarified = \"\"\n    clarified_summaries.append(clarified)\n\nsample_df['clarified_summary'] = clarified_summaries\n\n# Initialize evaluation tools\nrouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nembed_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\n# Compute embeddings\noriginal_texts = sample_df['TEXT'].tolist()\nclarified_texts = sample_df['clarified_summary'].tolist()\n\noriginal_embeddings = embed_model.encode(original_texts, convert_to_tensor=True, batch_size=16)\nclarified_embeddings = embed_model.encode(clarified_texts, convert_to_tensor=True, batch_size=16)\n\nrougeL_scores = []\ncosine_scores = []\n\nfor orig, clar, orig_emb, clar_emb in tqdm(zip(original_texts, clarified_texts, original_embeddings, clarified_embeddings), total=len(original_texts)):\n    rougeL_score = rouge.score(orig, clar)['rougeL'].fmeasure\n    rougeL_scores.append(rougeL_score)\n    cosine_sim = util.cos_sim(orig_emb, clar_emb).item()\n    cosine_scores.append(cosine_sim)\n\navg_rougeL = np.mean(rougeL_scores)\navg_cosine_similarity = np.mean(cosine_scores)\n\nprint(f\"\\nAverage ROUGE-L: {avg_rougeL:.4f}\")\nprint(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n\n# BLEU evaluation\nbleu = sacrebleu.corpus_bleu(clarified_texts, [original_texts])\nprint(f\"Average BLEU: {bleu.score:.4f}\")\n\n# BERTScore evaluation\nP, R, F1 = bertscore(clarified_texts, original_texts, lang=\"en\")\nprint(f\"Average BERTScore F1: {F1.mean().item():.4f}\")\n\n# Show example outputs\nprint(sample_df[['TEXT', 'clarified_summary']].head())\n\n# Save to CSV\nsample_df.to_csv(\"clarified_medical_reports_medalpaca_evaluation.csv\", index=False)\nprint(\"Saved evaluations to clarified_medical_reports_medalpaca_evaluation.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T18:33:20.101147Z","iopub.execute_input":"2025-07-28T18:33:20.101379Z","iopub.status.idle":"2025-07-28T18:43:04.611699Z","shell.execute_reply.started":"2025-07-28T18:33:20.101356Z","shell.execute_reply":"2025-07-28T18:43:04.610987Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"2025-07-28 18:35:03.656131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753727703.841503      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753727703.897960      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"494c048ffbbe4e10aeffd95b2890c8c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f734e34011144fc1b1fc088f9c0d85db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1ad1382fb547afaf00a8472d5d8d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32301501feeb45c6a56ec5cb75ccb6f3"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/542 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3e8279ee9749e8a2c76c7eafcf9ded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"073515d24c1a4c17adda0b271aa5b153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e9a45b5ddae41a2bfd4ce51cc55961f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/7.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e99660861d430a9ff203b5bedbb0c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/9.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22aa75cf9edb45219187770e28039f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/9.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8925b1b6367a41efb37a0e554b663682"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['pad_token_id']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['pad_token_id']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22cb5920eadd4e4582b872026036cfc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b5d1ea13564cfba3fd732a4fa42fc5"}},"metadata":{}},{"name":"stderr","text":"Clarifying Medical Reports: 100%|██████████| 30/30 [03:53<00:00,  7.79s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12555dcaf6548b18c7ec32f77b75989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fbc00cfad4b403d8e580936428c1da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf1370260fc4b35b48707394a7c6b17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90a06e486bc942bf8e5aae07e6d726d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b14eb582154c199674d614005d3d17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3576c627a8440eb1fe75c6baa127e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33decd378a049a1a0f2ceb108b8ace2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad46ebc461164e69a3176325a598e7bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9261d6b92bb443fd9f09b7a3fabd82fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f77e46a83f64020aa11b33cf588bc72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a9450c4faf43adaa87f684275df617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677da9cc07e242cca9eee4abd003de58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11960cb38da141f48a113ac2e88c1298"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 30/30 [00:06<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage ROUGE-L: 0.4272\nAverage Cosine Similarity: 0.9574\nAverage BLEU: 4.9406\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e040377bc0477e8ce56a1f8a0786ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae53456d505044899e0cef21ef0991de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b4fd8c6aa24419b72e705b1149929b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6db8b6858e4b4aa185313df47b73f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a5c67331ff4d6fa8d55fba77a8614b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b821284390bc499ab975565eff6b5338"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Average BERTScore F1: 0.9752\n                                                TEXT  \\\n0  Admission Date:  [**2192-5-20**]              ...   \n1  Admission Date:  [**2137-12-5**]              ...   \n2  Admission Date:  [**2152-10-19**]             ...   \n3  Admission Date:  [**2129-5-23**]              ...   \n4  Admission Date:  [**2184-6-23**]              ...   \n\n                                   clarified_summary  \n0  ### Instruction:\\nSummarize the following medi...  \n1  ### Instruction:\\nSummarize the following medi...  \n2  ### Instruction:\\nSummarize the following medi...  \n3  ### Instruction:\\nSummarize the following medi...  \n4  ### Instruction:\\nSummarize the following medi...  \nSaved evaluations to clarified_medical_reports_medalpaca_evaluation.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required packages\n!pip install torch transformers pandas tqdm sentence-transformers rouge-score sacremoses sacrebleu bert-score --quiet\n\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom rouge_score import rouge_scorer\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bertscore\nimport sacrebleu\n\n# Load EleutherAI GPT-Neo model and tokenizer\nmodel_name = \"EleutherAI/gpt-neo-1.3B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForCausalLM.from_pretrained(model_name).to(device)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.eval()\n\n# Load dataset and sample subset\ndf = pd.read_csv(\"/kaggle/input/precription/health prescription data.csv\")\ndf = df[['SUBJECT_ID', 'ROW_ID', 'HADM_ID', 'CATEGORY', 'ADMISSION_TYPE', 'DIAGNOSIS', 'TEXT']].dropna(subset=['TEXT']).reset_index(drop=True)\nsample_df = df.sample(n=30, random_state=42).reset_index(drop=True)\n\n# Clarification function for GPT-Neo\ndef clarify_text_gptneo(text, max_new_tokens=100):\n    prompt = f\"Summarize the following medical report clearly and concisely:\\n{text}\\nSummary:\"\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024 - max_new_tokens,\n        padding=\"max_length\"\n    ).to(device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id\n    )\n\n    clarified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return clarified_text.replace(prompt, \"\").strip()\n\n# Clarify medical reports\nclarified_summaries = []\nfor report in tqdm(sample_df['TEXT'], desc=\"Clarifying Medical Reports\"):\n    try:\n        clarified = clarify_text_gptneo(report)\n    except Exception:\n        clarified = \"\"\n    clarified_summaries.append(clarified)\n\nsample_df['clarified_summary'] = clarified_summaries\n\n# Evaluation tools\nrouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nembed_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\n# Compute embeddings\noriginal_texts = sample_df['TEXT'].tolist()\nclarified_texts = sample_df['clarified_summary'].tolist()\n\noriginal_embeddings = embed_model.encode(original_texts, convert_to_tensor=True, batch_size=16)\nclarified_embeddings = embed_model.encode(clarified_texts, convert_to_tensor=True, batch_size=16)\n\nrougeL_scores = []\ncosine_scores = []\n\nfor orig, clar, orig_emb, clar_emb in tqdm(zip(original_texts, clarified_texts, original_embeddings, clarified_embeddings), total=len(original_texts)):\n    rougeL_score = rouge.score(orig, clar)['rougeL'].fmeasure\n    rougeL_scores.append(rougeL_score)\n    cosine_sim = util.cos_sim(orig_emb, clar_emb).item()\n    cosine_scores.append(cosine_sim)\n\navg_rougeL = np.mean(rougeL_scores)\navg_cosine_similarity = np.mean(cosine_scores)\n\nprint(f\"\\nAverage ROUGE-L: {avg_rougeL:.4f}\")\nprint(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n\n# BLEU evaluation\nbleu = sacrebleu.corpus_bleu(clarified_texts, [original_texts])\nprint(f\"Average BLEU: {bleu.score:.4f}\")\n\n# BERTScore evaluation\nP, R, F1 = bertscore(clarified_texts, original_texts, lang=\"en\")\nprint(f\"Average BERTScore F1: {F1.mean().item():.4f}\")\n\n# Show example outputs\nprint(sample_df[['TEXT', 'clarified_summary']].head())\n\n# Save to CSV\nsample_df.to_csv(\"clarified_medical_reports_gptneo_evaluation.csv\", index=False)\nprint(\"Saved evaluations to clarified_medical_reports_gptneo_evaluation.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T06:22:12.882193Z","iopub.execute_input":"2025-07-29T06:22:12.882831Z","iopub.status.idle":"2025-07-29T06:26:35.459978Z","shell.execute_reply.started":"2025-07-29T06:22:12.882783Z","shell.execute_reply":"2025-07-29T06:26:35.459153Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"2025-07-29 06:23:40.237037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753770220.395920      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753770220.443712      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a0c82483fb9447b973f7e92ce8b991f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420f4f43e19c42c8a34559958b77bc89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37e406815da24dedba8e2c7bdb533287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34aa1003be82415ab8b32354eadb0173"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2bfddd9dedc4fc6a5bb8007c53b945d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2193bb593294d5ab0c78b154e8e56c5"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\nClarifying Medical Reports: 100%|██████████| 30/30 [01:29<00:00,  2.98s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae91efe60550464ca8a55c00bb97eff2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a639f2fd8844c448a4dad6e02aed51e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c35421678f4403b6901d3cac224216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"152f32d3afed40b3a1a617ab2bc8c0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed11cd6d358247838155ef69bfcf864e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d3de5e8007c4f439d5e3a555c037990"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccf100e114545198c2a3cea51be8910"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c62fb08b7964afc9c9db6d17b13c38d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce9c81d134b4a0b91835c29a6a29570"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c66c53ec1ee49c8b079f77d25fb1b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dcb2432b884e8d880ba1f805424479"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5152a48bbc8f4575b6749744dc89df1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ad6090e5a734c149a7a6cd1445961d7"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 30/30 [00:07<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage ROUGE-L: 0.4793\nAverage Cosine Similarity: 0.9732\nAverage BLEU: 8.5063\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e87ac2c226a4b4196c5a2d77531a658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93d4f36cbee44717b6f5af89a78deb35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e34cb97a42ca491ba585a1208512ce97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"587c710433f84169bccf6909e7f2a0a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416c7f2b9c664135930ad936c3e44d78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b2d481664447218f0332a530add728"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Average BERTScore F1: 0.9827\n                                                TEXT  \\\n0  Admission Date:  [**2192-5-20**]              ...   \n1  Admission Date:  [**2137-12-5**]              ...   \n2  Admission Date:  [**2152-10-19**]             ...   \n3  Admission Date:  [**2129-5-23**]              ...   \n4  Admission Date:  [**2184-6-23**]              ...   \n\n                                   clarified_summary  \n0  Summarize the following medical report clearly...  \n1  Summarize the following medical report clearly...  \n2  Summarize the following medical report clearly...  \n3  Summarize the following medical report clearly...  \n4  Summarize the following medical report clearly...  \nSaved evaluations to clarified_medical_reports_gptneo_evaluation.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required packages\n!pip install torch transformers pandas tqdm sentence-transformers rouge-score sacremoses sacrebleu bert-score --quiet\n\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom rouge_score import rouge_scorer\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bertscore\nimport sacrebleu\n\n# Load MedLLaMA2 model and tokenizer\nmodel_name = \"llSourcell/medllama2_7b\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.eval()\n\n# Load dataset and sample 30 entries\ndf = pd.read_csv(\"/kaggle/input/precription/health prescription data.csv\")\ndf = df[['SUBJECT_ID', 'ROW_ID', 'HADM_ID', 'CATEGORY', 'ADMISSION_TYPE', 'DIAGNOSIS', 'TEXT']].dropna(subset=['TEXT']).reset_index(drop=True)\nsample_df = df.sample(n=30, random_state=42).reset_index(drop=True)\n\n# Clarification function for MedLLaMA2\ndef clarify_text_medllama(text, max_new_tokens=100):\n    prompt = f\"### Instruction:\\nSummarize the following medical report clearly and concisely.\\n\\n### Input:\\n{text}\\n\\n### Response:\"\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024 - max_new_tokens,\n        padding=\"max_length\"\n    ).to(model.device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id\n    )\n\n    clarified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return clarified_text.replace(prompt, \"\").strip()\n\n# Clarify medical reports\nclarified_summaries = []\nfor report in tqdm(sample_df['TEXT'], desc=\"Clarifying Medical Reports\"):\n    try:\n        clarified = clarify_text_medllama(report)\n    except Exception:\n        clarified = \"\"\n    clarified_summaries.append(clarified)\n\nsample_df['clarified_summary'] = clarified_summaries\n\n# Evaluation tools\nrouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nembed_model = SentenceTransformer('all-MiniLM-L6-v2', device=model.device)\n\n# Compute embeddings\noriginal_texts = sample_df['TEXT'].tolist()\nclarified_texts = sample_df['clarified_summary'].tolist()\n\noriginal_embeddings = embed_model.encode(original_texts, convert_to_tensor=True, batch_size=16)\nclarified_embeddings = embed_model.encode(clarified_texts, convert_to_tensor=True, batch_size=16)\n\nrougeL_scores = []\ncosine_scores = []\n\nfor orig, clar, orig_emb, clar_emb in tqdm(zip(original_texts, clarified_texts, original_embeddings, clarified_embeddings), total=len(original_texts)):\n    rougeL_score = rouge.score(orig, clar)['rougeL'].fmeasure\n    rougeL_scores.append(rougeL_score)\n    cosine_sim = util.cos_sim(orig_emb, clar_emb).item()\n    cosine_scores.append(cosine_sim)\n\navg_rougeL = np.mean(rougeL_scores)\navg_cosine_similarity = np.mean(cosine_scores)\n\nprint(f\"\\nAverage ROUGE-L: {avg_rougeL:.4f}\")\nprint(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n\n# BLEU evaluation\nbleu = sacrebleu.corpus_bleu(clarified_texts, [original_texts])\nprint(f\"Average BLEU: {bleu.score:.4f}\")\n\n# BERTScore evaluation\nP, R, F1 = bertscore(clarified_texts, original_texts, lang=\"en\")\nprint(f\"Average BERTScore F1: {F1.mean().item():.4f}\")\n\n# Show example outputs\nprint(sample_df[['TEXT', 'clarified_summary']].head())\n\n# Save to CSV\nsample_df.to_csv(\"clarified_medical_reports_medllama2_evaluation.csv\", index=False)\nprint(\"Saved evaluations to clarified_medical_reports_medllama2_evaluation.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:02:13.243006Z","iopub.execute_input":"2025-07-29T08:02:13.243384Z","iopub.status.idle":"2025-07-29T10:10:46.154313Z","shell.execute_reply.started":"2025-07-29T08:02:13.243350Z","shell.execute_reply":"2025-07-29T10:10:46.152139Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m124.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m87.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"2025-07-29 08:03:58.722906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753776239.058304      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753776239.158088      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f79b41c2fe9e459fb60304e290338835"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39e2ae80322430bb6ea5b341c672b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fedd1b0b8e314fa5a56e0391469a15f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1da0b2d21b14014bd7102444641f60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da87b20a03f04267a8e4cbd9d11dacf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a37350a06574f59b1c4a7571f961d03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d28169b23e430a8b4cc10ecada565f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595e8a5aaf514cdeba680cf21b266dff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae6b5b5d15b4c328f5d5cbea2cd8c7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e9f02bf79ee4923bc26e8d41db33b8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e952e21ee24a1aa47abb64c5aa1bc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ae7280d7a641a581b981a225d6dd7d"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:   0%|          | 0/30 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:   3%|▎         | 1/30 [04:46<2:18:41, 286.96s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:   7%|▋         | 2/30 [08:52<2:02:35, 262.68s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  10%|█         | 3/30 [12:52<1:53:32, 252.32s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  13%|█▎        | 4/30 [16:50<1:46:56, 246.78s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  17%|█▋        | 5/30 [20:55<1:42:29, 245.96s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  20%|██        | 6/30 [24:59<1:38:10, 245.43s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  23%|██▎       | 7/30 [29:02<1:33:42, 244.44s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  27%|██▋       | 8/30 [33:04<1:29:20, 243.68s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  30%|███       | 9/30 [37:17<1:26:21, 246.71s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  33%|███▎      | 10/30 [41:29<1:22:43, 248.20s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  37%|███▋      | 11/30 [45:30<1:17:54, 246.03s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  40%|████      | 12/30 [49:29<1:13:09, 243.89s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  43%|████▎     | 13/30 [53:33<1:09:05, 243.86s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  47%|████▋     | 14/30 [57:36<1:04:58, 243.64s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  50%|█████     | 15/30 [1:01:38<1:00:46, 243.10s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  53%|█████▎    | 16/30 [1:05:36<56:23, 241.69s/it]  The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  57%|█████▋    | 17/30 [1:09:38<52:24, 241.86s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  60%|██████    | 18/30 [1:13:41<48:25, 242.09s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  63%|██████▎   | 19/30 [1:17:39<44:09, 240.90s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  67%|██████▋   | 20/30 [1:21:39<40:05, 240.54s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  70%|███████   | 21/30 [1:25:40<36:05, 240.63s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  73%|███████▎  | 22/30 [1:29:39<32:03, 240.42s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  77%|███████▋  | 23/30 [1:33:38<27:58, 239.85s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  80%|████████  | 24/30 [1:37:35<23:53, 238.89s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  83%|████████▎ | 25/30 [1:41:32<19:52, 238.41s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  87%|████████▋ | 26/30 [1:45:42<16:07, 241.89s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  90%|█████████ | 27/30 [1:49:43<12:05, 241.74s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  93%|█████████▎| 28/30 [1:53:43<08:02, 241.06s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports:  97%|█████████▋| 29/30 [1:57:47<04:02, 242.02s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nClarifying Medical Reports: 100%|██████████| 30/30 [2:01:45<00:00, 243.52s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd607a6f3f974e3bbf8baaa404eb4277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b53d92300e4820a8cf3049b8d5b0a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6268777e42514b49bd701782e4e55dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685105d61e494540881facc58e992379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ea14f92a894b8b91eb5461cfe91903"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ac11d6b03245f3b845acbc8e83375e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d807d9bfbc84c628eb7732e43fa543f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c2a316169f487f9401f3f32b2aade8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ddeb67aa5924abfafa0c60b9951e98e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7034457dae4ea6a2b2cb2b8c514ac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31762145fd346aea6134b29c74a3804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37268d0657e4c9984bd0d39adfd113b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3259c68bb1fa44c097bd74e4d146c5fa"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 30/30 [00:07<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage ROUGE-L: 0.4287\nAverage Cosine Similarity: 0.9574\nAverage BLEU: 5.0633\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b65fb4367b540fbb9b0d4d28c3851e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ec0de2daf594a149b04812c76bbdc72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a579786b3e3405682e6b77a894a9a6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b54d7f25204d8c8a58c198e84f5dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b468c6eba23845a4ac416175d82d167f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4f12dec6b544926ad12a0dbe43e0b20"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Average BERTScore F1: 0.9752\n                                                TEXT  \\\n0  Admission Date:  [**2192-5-20**]              ...   \n1  Admission Date:  [**2137-12-5**]              ...   \n2  Admission Date:  [**2152-10-19**]             ...   \n3  Admission Date:  [**2129-5-23**]              ...   \n4  Admission Date:  [**2184-6-23**]              ...   \n\n                                   clarified_summary  \n0  ### Instruction:\\nSummarize the following medi...  \n1  ### Instruction:\\nSummarize the following medi...  \n2  ### Instruction:\\nSummarize the following medi...  \n3  ### Instruction:\\nSummarize the following medi...  \n4  ### Instruction:\\nSummarize the following medi...  \nSaved evaluations to clarified_medical_reports_medllama2_evaluation.csv\n","output_type":"stream"}],"execution_count":1}]}